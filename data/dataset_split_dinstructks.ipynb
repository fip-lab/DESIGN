{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# Load the datasets\n",
    "with open('./train/labels.json', 'r') as file:\n",
    "    labels_data = json.load(file)\n",
    "with open('./train/logs.json', 'r') as file:\n",
    "    logs_data = json.load(file)\n",
    "with open('./train/logs_aspect.json', 'r') as file:\n",
    "    logs_aspect_data = json.load(file)\n",
    "with open('./train/triple.json', 'r') as file:\n",
    "    triple_data = json.load(file)\n",
    "\n",
    "# Ensure the datasets have the same length\n",
    "assert len(labels_data) == len(logs_data), \"The datasets do not match in length.\"\n",
    "\n",
    "# Helper function to categorize the length of the knowledge field\n",
    "def knowledge_length_category(entry):\n",
    "    if 'knowledge' not in entry or not entry['knowledge']:\n",
    "        return 'none'\n",
    "    length = len(entry['knowledge'])\n",
    "    if length <= 3:\n",
    "        return 'between_1_and_3'\n",
    "    elif 4 <= length <= 6:\n",
    "        return 'between_4_and_6'\n",
    "    else:\n",
    "        return 'more_than_6'\n",
    "\n",
    "# Prepare the stratification variable based on labels_data\n",
    "knowledge_categories = [knowledge_length_category(entry) for entry in labels_data]\n",
    "targets = [entry['target'] for entry in labels_data]\n",
    "\n",
    "# Generate indices for the split using stratification based on the knowledge category and the target label\n",
    "train_indices, test_indices = next(StratifiedKFold(n_splits=4, shuffle=True, random_state=42).split(labels_data, knowledge_categories))\n",
    "\n",
    "# Split both datasets using the generated indices\n",
    "train_labels = [labels_data[i] for i in train_indices]\n",
    "test_labels = [labels_data[i] for i in test_indices]\n",
    "train_logs = [logs_data[i] for i in train_indices]\n",
    "test_logs = [logs_data[i] for i in test_indices]\n",
    "train_logs_aspect = [logs_aspect_data[i] for i in train_indices]\n",
    "test_logs_aspect = [logs_aspect_data[i] for i in test_indices]\n",
    "train_triple = [triple_data[i] for i in train_indices]\n",
    "test_triple = [triple_data[i] for i in test_indices]\n",
    "# Save the split datasets\n",
    "with open('./Dynamic_InstructKS_Dataset_triple_based/train/labels.json', 'w') as file:\n",
    "    json.dump(train_labels, file, indent=4)\n",
    "with open('./Dynamic_InstructKS_Dataset_triple_based/train/logs.json', 'w') as file:\n",
    "    json.dump(train_logs, file, indent=4)\n",
    "with open('./Dynamic_InstructKS_Dataset_triple_based/train/logs_aspect.json', 'w') as file:\n",
    "    json.dump(train_logs_aspect, file, indent=4)\n",
    "with open('./Dynamic_InstructKS_Dataset_triple_based/train/triple.json', 'w') as file:\n",
    "    json.dump(train_triple, file, indent=4)\n",
    "\n",
    "with open('./Dynamic_InstructKS_Dataset_triple_based/resource/labels.json', 'w') as file:\n",
    "    json.dump(test_labels, file, indent=4)\n",
    "with open('./Dynamic_InstructKS_Dataset_triple_based/resource/logs.json', 'w') as file:\n",
    "    json.dump(test_logs, file, indent=4)\n",
    "with open('./Dynamic_InstructKS_Dataset_triple_based/resource/logs_aspect.json', 'w') as file:\n",
    "    json.dump(test_logs_aspect, file, indent=4)\n",
    "with open('./Dynamic_InstructKS_Dataset_triple_based/resource/triple.json', 'w') as file:\n",
    "    json.dump(test_triple, file, indent=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Statistics: {'total_entries': 21323, 'knowledge_length_counts': {'none': 10247, 'between_1_and_3': 5909, 'between_4_and_6': 3911, 'more_than_6': 1256}, 'knowledge_length_proportions': {'none': 0.4805608966843315, 'between_1_and_3': 0.2771186043239694, 'between_4_and_6': 0.18341696759367818, 'more_than_6': 0.05890353139802092}}\n",
      "Testing Data Statistics: {'total_entries': 7108, 'knowledge_length_counts': {'none': 3416, 'between_1_and_3': 1970, 'between_4_and_6': 1304, 'more_than_6': 418}, 'knowledge_length_proportions': {'none': 0.4805852560495217, 'between_1_and_3': 0.2771525042205965, 'between_4_and_6': 0.18345526167698367, 'more_than_6': 0.05880697805289814}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Make sure to define the knowledge_length_category function as provided above.\n",
    "\n",
    "def calculate_statistics(dataset):\n",
    "    stats = {\n",
    "        'total_entries': len(dataset),\n",
    "        'knowledge_length_counts': {\n",
    "            'none': 0,\n",
    "            'between_1_and_3': 0,\n",
    "            'between_4_and_6': 0,\n",
    "            'more_than_6': 0,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for entry in dataset:\n",
    "        category = knowledge_length_category(entry)\n",
    "        stats['knowledge_length_counts'][category] += 1\n",
    "    \n",
    "    stats['knowledge_length_proportions'] = {\n",
    "        k: v / stats['total_entries'] for k, v in stats['knowledge_length_counts'].items()\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Load the datasets\n",
    "with open('./ynamic_InstructKS_Dataset_triple_based/train/train_labels.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "with open('./ynamic_InstructKS_Dataset_triple_based/resource/labels.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "# Calculate and print the statistics\n",
    "train_stats = calculate_statistics(train_data)\n",
    "test_stats = calculate_statistics(test_data)\n",
    "\n",
    "print(\"Training Data Statistics:\", train_stats)\n",
    "print(\"Testing Data Statistics:\", test_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28431\n"
     ]
    }
   ],
   "source": [
    "with open('./train/labels.json', 'r') as file:\n",
    "    labels_data = json.load(file)\n",
    "print(len(labels_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowdialog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
